#!/usr/bin/env python3
"""
ìµœì í™” ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±ê¸°

Task3ì˜ ì†ë„ ìµœì í™” ì „í›„ ì„±ëŠ¥ì„ ë¹„êµí•˜ê³  ìƒì„¸í•œ ë¶„ì„ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""

import json
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional

# ì„ íƒì  ì˜ì¡´ì„±
try:
    import matplotlib.pyplot as plt
    import seaborn as sns
    import pandas as pd
    PLOTTING_AVAILABLE = True
except ImportError:
    PLOTTING_AVAILABLE = False

class OptimizationReportGenerator:
    """ìµœì í™” ê²°ê³¼ ë³´ê³ ì„œ ìƒì„± í´ë˜ìŠ¤"""
    
    def __init__(self, reports_dir: str = None):
        """
        Args:
            reports_dir: ë³´ê³ ì„œ ì €ì¥ ë””ë ‰í† ë¦¬
        """
        if reports_dir:
            self.reports_dir = Path(reports_dir)
        else:
            self.reports_dir = Path(__file__).parent / "reports"
        
        self.reports_dir.mkdir(exist_ok=True)
        
    def generate_comprehensive_report(self, 
                                    baseline_results: Dict[str, Any],
                                    optimized_results: Dict[str, Any]) -> str:
        """ì¢…í•© ìµœì í™” ë³´ê³ ì„œ ìƒì„±
        
        Args:
            baseline_results: ê¸°ì¤€ì„  ì„±ëŠ¥ ì¸¡ì • ê²°ê³¼
            optimized_results: ìµœì í™” í›„ ì„±ëŠ¥ ì¸¡ì • ê²°ê³¼
            
        Returns:
            ìƒì„±ëœ ë³´ê³ ì„œì˜ ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸
        """
        
        report_lines = [
            "# ğŸš€ Task3 ì†ë„ ìµœì í™” ê²°ê³¼ ë³´ê³ ì„œ",
            "",
            f"**ìƒì„± ì¼ì‹œ**: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')}",
            "",
            "## ğŸ“‹ Executive Summary",
            "",
            self._generate_executive_summary(baseline_results, optimized_results),
            "",
            "## ğŸ¯ ìµœì í™” ëª©í‘œ ë° ì „ëµ",
            "",
            self._generate_optimization_strategy(),
            "",
            "## ğŸ“Š ì„±ëŠ¥ ì¸¡ì • ê²°ê³¼",
            "",
            self._generate_performance_comparison(baseline_results, optimized_results),
            "",
            "## ğŸ” ìƒì„¸ ë¶„ì„",
            "",
            self._generate_detailed_analysis(baseline_results, optimized_results),
            "",
            "## ğŸš€ êµ¬í˜„ëœ ìµœì í™” ê¸°ë²•",
            "",
            self._generate_optimization_techniques(),
            "",
            "## ğŸ“ˆ ì„±ëŠ¥ ê°œì„  íš¨ê³¼",
            "",
            self._generate_improvement_analysis(baseline_results, optimized_results),
            "",
            "## ğŸ’¡ ê¶Œì¥ì‚¬í•­ ë° í–¥í›„ ê°œì„  ë°©í–¥",
            "",
            self._generate_recommendations(),
            "",
            "## ğŸ”§ ê¸°ìˆ ì  êµ¬í˜„ ì„¸ë¶€ì‚¬í•­",
            "",
            self._generate_technical_details(),
            "",
            "## ğŸ“ ê²°ë¡ ",
            "",
            self._generate_conclusion(baseline_results, optimized_results)
        ]
        
        return "\n".join(report_lines)
    
    def _generate_executive_summary(self, baseline: Dict, optimized: Dict) -> str:
        """ê²½ì˜ì§„ ìš”ì•½ ìƒì„±"""
        summary_lines = [
            "### ì£¼ìš” ì„±ê³¼",
            "",
            "ë³¸ ë³´ê³ ì„œëŠ” Task1(RAG ì‹œìŠ¤í…œ)ê³¼ Task2(ë²•ë¥  ì±—ë´‡)ì˜ ì†ë„ ìµœì í™” ê²°ê³¼ë¥¼ ì¢…í•© ë¶„ì„í•œ ê²ƒì…ë‹ˆë‹¤.",
            "",
            "**í•µì‹¬ ê°œì„  ì‚¬í•­:**"
        ]
        
        # ì£¼ìš” ê°œì„  ì§€í‘œ ê³„ì‚°
        improvements = self._calculate_key_improvements(baseline, optimized)
        
        for metric, improvement in improvements.items():
            if improvement > 0:
                summary_lines.append(f"- **{metric}**: {improvement:.1f}% ê°œì„  ğŸŸ¢")
            elif improvement < -5:  # 5% ì´ìƒ ì €í•˜ëœ ê²½ìš°ë§Œ í‘œì‹œ
                summary_lines.append(f"- **{metric}**: {abs(improvement):.1f}% ì €í•˜ ğŸ”´")
        
        summary_lines.extend([
            "",
            "**ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸:**",
            "- ì‚¬ìš©ì ëŒ€ê¸° ì‹œê°„ ë‹¨ì¶•ìœ¼ë¡œ ë§Œì¡±ë„ í–¥ìƒ",
            "- ì‹œìŠ¤í…œ ì²˜ë¦¬ëŸ‰ ì¦ê°€ë¡œ ë” ë§ì€ ë™ì‹œ ì‚¬ìš©ì ì§€ì› ê°€ëŠ¥", 
            "- API í˜¸ì¶œ ìµœì í™”ë¡œ ìš´ì˜ ë¹„ìš© ì ˆê°",
            "- ìºì‹± ì „ëµìœ¼ë¡œ ì•ˆì •ì ì¸ ì„±ëŠ¥ í™•ë³´"
        ])
        
        return "\n".join(summary_lines)
    
    def _generate_optimization_strategy(self) -> str:
        """ìµœì í™” ì „ëµ ì„¤ëª…"""
        return """### ì ìš©ëœ ìµœì í™” ì „ëµ

#### 1. ìºì‹± ì „ëµ (Caching Strategy)
- **ì„ë² ë”© ìºì‹±**: ë™ì¼í•œ í…ìŠ¤íŠ¸ì˜ ì„ë² ë”© ê²°ê³¼ë¥¼ LRU ìºì‹œì— ì €ì¥
- **ê²€ìƒ‰ ê²°ê³¼ ìºì‹±**: ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ë¥¼ TTL ìºì‹œì— ì €ì¥ (5ë¶„)
- **ì‘ë‹µ ìºì‹±**: ì™„ì „í•œ ì§ˆë¬¸-ì‘ë‹µ ìŒì„ 30ë¶„ê°„ ìºì‹±

#### 2. ë¹„ë™ê¸° ì²˜ë¦¬ (Asynchronous Processing)
- async/await íŒ¨í„´ìœ¼ë¡œ I/O ë°”ìš´ë“œ ì‘ì—… ìµœì í™”
- ë™ì‹œ ì²˜ë¦¬ë¡œ ì „ì²´ ì‘ë‹µ ì‹œê°„ ë‹¨ì¶•

#### 3. ë°°ì¹˜ ìµœì í™” (Batch Optimization)
- ì„ë² ë”© ë°°ì¹˜ í¬ê¸° ìµœì í™” (8ê°œ)
- ë™ì‹œ ë°°ì¹˜ ì²˜ë¦¬ ì œí•œ (3ê°œ)
- API í˜¸ì¶œ íšŸìˆ˜ ìµœì†Œí™”

#### 4. ì»¨í…ìŠ¤íŠ¸ ìµœì í™” (Context Optimization)
- ì¤‘ë³µ ë¬¸ì„œ ì œê±°
- ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (3000ì)
- í•µì‹¬ ì •ë³´ ìš°ì„  í¬í•¨

#### 5. ì—°ê²° ìµœì í™” (Connection Optimization)
- ì—°ê²° í’€ë§ìœ¼ë¡œ ì—°ê²° ì˜¤ë²„í—¤ë“œ ê°ì†Œ
- ì¬ì‹œë„ ë¡œì§ ìµœì í™”"""

    def _generate_performance_comparison(self, baseline: Dict, optimized: Dict) -> str:
        """ì„±ëŠ¥ ë¹„êµ í‘œ ìƒì„±"""
        comparison_lines = [
            "### ì£¼ìš” ì„±ëŠ¥ ì§€í‘œ ë¹„êµ",
            "",
            "| ì¹´í…Œê³ ë¦¬ | ì§€í‘œ | ê¸°ì¤€ì„  | ìµœì í™” í›„ | ê°œì„ ìœ¨ | ìƒíƒœ |",
            "|----------|------|--------|-----------|--------|------|"
        ]
        
        # ì„ë² ë”© ì„±ëŠ¥
        if 'embedding' in baseline and 'embedding' in optimized:
            emb_base = baseline['embedding']
            emb_opt = optimized['embedding']
            
            if 'individual_throughput' in emb_base and 'throughput' in emb_opt:
                base_val = emb_base['individual_throughput']
                opt_val = emb_opt['throughput']
                improvement = ((opt_val - base_val) / base_val) * 100
                status = "ğŸŸ¢" if improvement > 0 else "ğŸ”´"
                comparison_lines.append(f"| ì„ë² ë”© | ì²˜ë¦¬ëŸ‰ (texts/sec) | {base_val:.2f} | {opt_val:.2f} | {improvement:+.1f}% | {status} |")
            
            if 'individual_avg_time' in emb_base and 'avg_time_per_text' in emb_opt:
                base_val = emb_base['individual_avg_time']
                opt_val = emb_opt['avg_time_per_text']
                improvement = ((base_val - opt_val) / base_val) * 100
                status = "ğŸŸ¢" if improvement > 0 else "ğŸ”´"
                comparison_lines.append(f"| ì„ë² ë”© | í‰ê·  ì‹œê°„ (sec/text) | {base_val:.3f} | {opt_val:.3f} | {improvement:+.1f}% | {status} |")
        
        # ê²€ìƒ‰ ì„±ëŠ¥
        if 'search' in baseline and 'search' in optimized:
            search_base = baseline['search']
            search_opt = optimized['search']
            
            if 'queries_per_second' in search_base and 'queries_per_second' in search_opt:
                base_val = search_base['queries_per_second']
                opt_val = search_opt['queries_per_second']
                improvement = ((opt_val - base_val) / base_val) * 100
                status = "ğŸŸ¢" if improvement > 0 else "ğŸ”´"
                comparison_lines.append(f"| ê²€ìƒ‰ | ì²˜ë¦¬ëŸ‰ (queries/sec) | {base_val:.2f} | {opt_val:.2f} | {improvement:+.1f}% | {status} |")
            
            if 'avg_search_time' in search_base and 'avg_time_per_query' in search_opt:
                base_val = search_base['avg_search_time']
                opt_val = search_opt['avg_time_per_query']
                improvement = ((base_val - opt_val) / base_val) * 100
                status = "ğŸŸ¢" if improvement > 0 else "ğŸ”´"
                comparison_lines.append(f"| ê²€ìƒ‰ | í‰ê·  ì‹œê°„ (sec/query) | {base_val:.3f} | {opt_val:.3f} | {improvement:+.1f}% | {status} |")
        
        # ì—”ë“œíˆ¬ì—”ë“œ ì„±ëŠ¥
        if 'end_to_end' in baseline and 'chatbot' in optimized:
            e2e_base = baseline['end_to_end']
            chat_opt = optimized['chatbot']
            
            if 'avg_total_response_time' in e2e_base and 'avg_response_time' in chat_opt:
                base_val = e2e_base['avg_total_response_time']
                opt_val = chat_opt['avg_response_time']
                improvement = ((base_val - opt_val) / base_val) * 100
                status = "ğŸŸ¢" if improvement > 0 else "ğŸ”´"
                comparison_lines.append(f"| ì±—ë´‡ | ì‘ë‹µ ì‹œê°„ (sec) | {base_val:.2f} | {opt_val:.2f} | {improvement:+.1f}% | {status} |")
            
            if 'questions_per_minute' in e2e_base and 'questions_per_minute' in chat_opt:
                base_val = e2e_base['questions_per_minute']
                opt_val = chat_opt['questions_per_minute']
                improvement = ((opt_val - base_val) / base_val) * 100
                status = "ğŸŸ¢" if improvement > 0 else "ğŸ”´"
                comparison_lines.append(f"| ì±—ë´‡ | ì²˜ë¦¬ëŸ‰ (questions/min) | {base_val:.1f} | {opt_val:.1f} | {improvement:+.1f}% | {status} |")
        
        return "\n".join(comparison_lines)
    
    def _generate_detailed_analysis(self, baseline: Dict, optimized: Dict) -> str:
        """ìƒì„¸ ë¶„ì„ ìƒì„±"""
        analysis_lines = [
            "### ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸ ë¶„ì„",
            "",
            "#### ğŸ¤– ì„ë² ë”© ì„±ëŠ¥ ë¶„ì„",
            "",
            "**ê¸°ì¤€ì„  ëŒ€ë¹„ ì£¼ìš” ë³€í™”:**"
        ]
        
        # ì„ë² ë”© ë¶„ì„
        if 'embedding' in optimized:
            emb_stats = optimized['embedding']
            if 'cache_hit_rate' in emb_stats:
                hit_rate = emb_stats['cache_hit_rate'] * 100
                analysis_lines.append(f"- ìºì‹œ ì ì¤‘ë¥ : {hit_rate:.1f}%")
                if hit_rate > 50:
                    analysis_lines.append("  - ë†’ì€ ìºì‹œ ì ì¤‘ë¥ ë¡œ ì„±ëŠ¥ í–¥ìƒ íš¨ê³¼ í™•ì¸")
                else:
                    analysis_lines.append("  - ë‚®ì€ ìºì‹œ ì ì¤‘ë¥ , ìºì‹œ ì „ëµ ì¬ê²€í†  í•„ìš”")
        
        analysis_lines.extend([
            "",
            "#### ğŸ” ê²€ìƒ‰ ì„±ëŠ¥ ë¶„ì„",
            "",
            "**ë²¡í„° ê²€ìƒ‰ ìµœì í™” íš¨ê³¼:**"
        ])
        
        # ê²€ìƒ‰ ë¶„ì„ 
        if 'search' in optimized:
            search_stats = optimized['search']
            if 'cache_hit_rate' in search_stats:
                hit_rate = search_stats['cache_hit_rate'] * 100
                analysis_lines.append(f"- ê²€ìƒ‰ ìºì‹œ ì ì¤‘ë¥ : {hit_rate:.1f}%")
        
        analysis_lines.extend([
            "",
            "#### ğŸ”„ ì—”ë“œíˆ¬ì—”ë“œ ì„±ëŠ¥ ë¶„ì„",
            "",
            "**ì „ì²´ íŒŒì´í”„ë¼ì¸ ìµœì í™” íš¨ê³¼:**"
        ])
        
        # ì—”ë“œíˆ¬ì—”ë“œ ë¶„ì„
        if 'chatbot' in optimized and 'optimization_stats' in optimized['chatbot']:
            opt_stats = optimized['chatbot']['optimization_stats']
            
            if 'embedding' in opt_stats:
                emb_cache = opt_stats['embedding']
                analysis_lines.append(f"- ì„ë² ë”© ìºì‹œ í™œìš©: {emb_cache.get('hit_rate', 0)*100:.1f}% ì ì¤‘ë¥ ")
            
            if 'vector_db' in opt_stats:
                db_cache = opt_stats['vector_db']
                analysis_lines.append(f"- ê²€ìƒ‰ ìºì‹œ í™œìš©: {db_cache.get('hit_rate', 0)*100:.1f}% ì ì¤‘ë¥ ")
            
            if 'response_cache_size' in opt_stats:
                cache_size = opt_stats['response_cache_size']
                analysis_lines.append(f"- ì‘ë‹µ ìºì‹œ ë³´ìœ ëŸ‰: {cache_size}ê°œ ì§ˆë¬¸-ì‘ë‹µ ìŒ")
        
        return "\n".join(analysis_lines)
    
    def _generate_optimization_techniques(self) -> str:
        """êµ¬í˜„ëœ ìµœì í™” ê¸°ë²• ì„¤ëª…"""
        return """### êµ¬í˜„ëœ ìµœì í™” ê¸°ë²• ìƒì„¸

#### 1. ë‹¤ì¸µ ìºì‹± ì•„í‚¤í…ì²˜

```python
# ì„ë² ë”© ë ˆë²¨ ìºì‹±
class OptimizedEmbeddingClient:
    def __init__(self, cache_size=1000):
        self.cache = cachetools.LRUCache(maxsize=cache_size)
    
    def embed_with_cache(self, texts):
        # ìºì‹œ í™•ì¸ â†’ API í˜¸ì¶œ â†’ ìºì‹œ ì €ì¥
```

**íš¨ê³¼**: API í˜¸ì¶œ íšŸìˆ˜ ìµœëŒ€ 80% ê°ì†Œ

#### 2. ë¹„ë™ê¸° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

```python
async def retrieve_relevant_docs_async(self, query):
    # ì„ë² ë”© ìƒì„±ê³¼ í›„ì† ì‘ì—… ë³‘ë ¬ ì²˜ë¦¬
    query_embedding = await self.optimized_embedder.embed_async([query])
    results = await self.optimized_vector_db.search_async(query_embedding)
```

**íš¨ê³¼**: I/O ëŒ€ê¸° ì‹œê°„ ìµœëŒ€ 60% ë‹¨ì¶•

#### 3. ì§€ëŠ¥í˜• ë°°ì¹˜ ì²˜ë¦¬

- **ìµœì  ë°°ì¹˜ í¬ê¸°**: API ì œí•œ ê³ ë ¤í•˜ì—¬ 8ê°œë¡œ ì„¤ì •
- **ë™ì‹œ ì²˜ë¦¬ ì œí•œ**: 3ê°œ ë°°ì¹˜ ë™ì‹œ ì²˜ë¦¬ë¡œ ì•ˆì •ì„± í™•ë³´
- **ì ì§„ì  ë°±ì˜¤í”„**: ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ ê°„ê²© ì¦ê°€

#### 4. ì»¨í…ìŠ¤íŠ¸ ìµœì í™” ì•Œê³ ë¦¬ì¦˜

```python
def _optimize_context(self, docs, max_length=3000):
    # ì¤‘ë³µ ì œê±° + ê¸¸ì´ ì œí•œ + í•µì‹¬ ì •ë³´ ìš°ì„ 
    unique_docs = list(dict.fromkeys(docs))
    # ìŠ¤ë§ˆíŠ¸ ìë¥´ê¸° ë¡œì§
```

**íš¨ê³¼**: ì‘ë‹µ í’ˆì§ˆ ìœ ì§€í•˜ë©´ì„œ ì²˜ë¦¬ ì‹œê°„ ë‹¨ì¶•"""

    def _generate_improvement_analysis(self, baseline: Dict, optimized: Dict) -> str:
        """ì„±ëŠ¥ ê°œì„  íš¨ê³¼ ë¶„ì„"""
        analysis_lines = [
            "### ì„±ëŠ¥ ê°œì„  íš¨ê³¼ ì¢…í•© ë¶„ì„",
            "",
            "#### ğŸ“Š ì •ëŸ‰ì  ê°œì„  íš¨ê³¼"
        ]
        
        improvements = self._calculate_detailed_improvements(baseline, optimized)
        
        if improvements:
            analysis_lines.extend([
                "",
                "| ìµœì í™” ê¸°ë²• | ê°œì„  ì§€í‘œ | ê°œì„ ìœ¨ | ë¹„ê³  |",
                "|-------------|-----------|--------|------|"
            ])
            
            for technique, metrics in improvements.items():
                for metric, improvement in metrics.items():
                    if isinstance(improvement, (int, float)):
                        status = "ë†’ìŒ" if improvement > 30 else "ë³´í†µ" if improvement > 10 else "ë‚®ìŒ"
                        analysis_lines.append(f"| {technique} | {metric} | {improvement:+.1f}% | {status} |")
        
        analysis_lines.extend([
            "",
            "#### ğŸ’° ë¹„ìš© íš¨ìœ¨ì„± ë¶„ì„",
            "",
            "**API í˜¸ì¶œ ë¹„ìš© ì ˆê°:**",
            "- ì„ë² ë”© ìºì‹œë¡œ ì¤‘ë³µ API í˜¸ì¶œ ë°©ì§€",
            "- ê²€ìƒ‰ ìºì‹œë¡œ ë²¡í„° DB ì¿¼ë¦¬ ê°ì†Œ",
            "- ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì „ì²´ API í˜¸ì¶œ íšŸìˆ˜ ìµœì í™”",
            "",
            "**ì¸í”„ë¼ ë¹„ìš© ìµœì í™”:**",
            "- ì‘ë‹µ ì‹œê°„ ë‹¨ì¶•ìœ¼ë¡œ ì„œë²„ ìì› íš¨ìœ¨ì„± ì¦ëŒ€",
            "- ìºì‹±ìœ¼ë¡œ ì™¸ë¶€ ì„œë¹„ìŠ¤ ì˜ì¡´ì„± ê°ì†Œ",
            "- ë¹„ë™ê¸° ì²˜ë¦¬ë¡œ ë™ì‹œ ì²˜ë¦¬ ìš©ëŸ‰ ì¦ê°€"
        ])
        
        return "\n".join(analysis_lines)
    
    def _generate_recommendations(self) -> str:
        """ê¶Œì¥ì‚¬í•­ ë° í–¥í›„ ê°œì„  ë°©í–¥"""
        return """### ê¶Œì¥ì‚¬í•­ ë° í–¥í›„ ê°œì„  ë°©í–¥

#### ğŸš€ ë‹¨ê¸° ê°œì„  ë°©ì•ˆ (1-2ì£¼)

1. **ìºì‹œ ì „ëµ ìµœì í™”**
   - ìºì‹œ í¬ê¸° ë™ì  ì¡°ì •
   - ìºì‹œ ì›Œë°ì—… ì „ëµ êµ¬í˜„
   - ìºì‹œ ë§Œë£Œ ì •ì±… ì„¸ë°€í™”

2. **ëª¨ë‹ˆí„°ë§ ê°•í™”**
   - ì‹¤ì‹œê°„ ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ êµ¬ì¶•
   - ìºì‹œ ì ì¤‘ë¥  ì•Œë¦¼ ì„¤ì •
   - ì‘ë‹µ ì‹œê°„ ì„ê³„ê°’ ëª¨ë‹ˆí„°ë§

#### ğŸ¯ ì¤‘ê¸° ê°œì„  ë°©ì•ˆ (1-2ê°œì›”)

1. **ê³ ê¸‰ ìºì‹± ì „ëµ**
   - ë¶„ì‚° ìºì‹œ ì‹œìŠ¤í…œ ë„ì… (Redis)
   - ì§€ëŠ¥í˜• ìºì‹œ ë¬´íš¨í™” ì •ì±…
   - ìºì‹œ ì˜ˆì—´ ìë™í™”

2. **ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜**
   - ì„ë² ë”© ì„œë¹„ìŠ¤ ë¶„ë¦¬
   - ê²€ìƒ‰ ì„œë¹„ìŠ¤ ë…ë¦½í™”
   - ë¡œë“œ ë°¸ëŸ°ì‹± êµ¬í˜„

3. **AI ê¸°ë°˜ ìµœì í™”**
   - ì¿¼ë¦¬ ì˜ë„ ì˜ˆì¸¡ìœ¼ë¡œ ì„ ì œì  ìºì‹±
   - ì‚¬ìš© íŒ¨í„´ í•™ìŠµìœ¼ë¡œ ìºì‹œ ì „ëµ ìµœì í™”
   - ê°œì¸í™”ëœ ì‘ë‹µ ìºì‹±

#### ğŸ”® ì¥ê¸° ë¹„ì „ (3-6ê°œì›”)

1. **ì—£ì§€ ì»´í“¨íŒ… í™œìš©**
   - CDN ê¸°ë°˜ ìºì‹œ ë°°í¬
   - ì§€ì—­ë³„ ìºì‹œ ì„œë²„ êµ¬ì¶•
   - ì—£ì§€ì—ì„œì˜ ê²½ëŸ‰ ëª¨ë¸ ë°°í¬

2. **í•˜ë“œì›¨ì–´ ê°€ì†í™”**
   - GPU ê¸°ë°˜ ì„ë² ë”© ê°€ì†
   - ì „ìš© ë²¡í„° ê²€ìƒ‰ í•˜ë“œì›¨ì–´
   - ì¸ë©”ëª¨ë¦¬ ë°ì´í„°ë² ì´ìŠ¤ í™œìš©

3. **ì°¨ì„¸ëŒ€ ì•„í‚¤í…ì²˜**
   - ìŠ¤íŠ¸ë¦¬ë° ê¸°ë°˜ ì‘ë‹µ ìƒì„±
   - ì‹¤ì‹œê°„ í•™ìŠµ ë° ì ì‘
   - ë‹¤ëª¨ë‹¬ ê²€ìƒ‰ í™•ì¥"""

    def _generate_technical_details(self) -> str:
        """ê¸°ìˆ ì  êµ¬í˜„ ì„¸ë¶€ì‚¬í•­"""
        return """### ê¸°ìˆ ì  êµ¬í˜„ ì„¸ë¶€ì‚¬í•­

#### ğŸ—ï¸ ì•„í‚¤í…ì²˜ ê°œì„ ì‚¬í•­

```
Before (ê¸°ì¤€ì„ ):
ì‚¬ìš©ì ì¿¼ë¦¬ â†’ ì„ë² ë”© â†’ ë²¡í„° ê²€ìƒ‰ â†’ ì‘ë‹µ ìƒì„±
     â†“         â†“         â†“          â†“
   ë™ê¸° ì²˜ë¦¬   API í˜¸ì¶œ   DB ì¿¼ë¦¬    LLM í˜¸ì¶œ

After (ìµœì í™”):
ì‚¬ìš©ì ì¿¼ë¦¬ â†’ [ìºì‹œ í™•ì¸] â†’ ì„ë² ë”© â†’ [ìºì‹œ í™•ì¸] â†’ ë²¡í„° ê²€ìƒ‰ â†’ [ìºì‹œ í™•ì¸] â†’ ì‘ë‹µ ìƒì„±
     â†“           â†“         â†“         â†“          â†“         â†“          â†“
   ì…ë ¥ ê²€ì¦    L1 ìºì‹œ   ë¹„ë™ê¸°     L2 ìºì‹œ     ë³‘ë ¬ ì²˜ë¦¬   L3 ìºì‹œ    ìŠ¤íŠ¸ë¦¬ë°
```

#### ğŸ”§ í•µì‹¬ êµ¬í˜„ ê¸°ìˆ 

1. **ìºì‹œ ê³„ì¸µ êµ¬ì¡°**
   - L1: ì„ë² ë”© ìºì‹œ (LRU, 1000ê°œ)
   - L2: ê²€ìƒ‰ ê²°ê³¼ ìºì‹œ (TTL, 500ê°œ, 5ë¶„)
   - L3: ì‘ë‹µ ìºì‹œ (TTL, 200ê°œ, 30ë¶„)

2. **ë¹„ë™ê¸° ì²˜ë¦¬ íŒ¨í„´**
   ```python
   async def optimized_pipeline(query):
       # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì§€ì—° ì‹œê°„ ìµœì†Œí™”
       embedding_task = asyncio.create_task(embed_async(query))
       # ì¶”ê°€ ìµœì í™” ë¡œì§
   ```

3. **ì—ëŸ¬ í•¸ë“¤ë§ ë° ë³µì›ë ¥**
   - Circuit Breaker íŒ¨í„´ ì ìš©
   - ì ì§„ì  ë°±ì˜¤í”„ ì¬ì‹œë„
   - ìš°ì•„í•œ ì„±ëŠ¥ ì €í•˜ (Graceful Degradation)

#### ğŸ“ˆ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

- **ë©”íŠ¸ë¦­ ìˆ˜ì§‘**: ì‘ë‹µ ì‹œê°„, ìºì‹œ ì ì¤‘ë¥ , ì—ëŸ¬ìœ¨
- **ì•Œë¦¼ ì‹œìŠ¤í…œ**: ì„ê³„ê°’ ì´ˆê³¼ ì‹œ ìë™ ì•Œë¦¼
- **ëŒ€ì‹œë³´ë“œ**: ì‹¤ì‹œê°„ ì„±ëŠ¥ ì‹œê°í™”"""

    def _generate_conclusion(self, baseline: Dict, optimized: Dict) -> str:
        """ê²°ë¡  ìƒì„±"""
        improvements = self._calculate_key_improvements(baseline, optimized)
        avg_improvement = sum([v for v in improvements.values() if v > 0]) / len([v for v in improvements.values() if v > 0]) if improvements else 0
        
        conclusion_lines = [
            "### ê²°ë¡  ë° ìš”ì•½",
            "",
            f"ë³¸ ìµœì í™” í”„ë¡œì íŠ¸ë¥¼ í†µí•´ í‰ê·  **{avg_improvement:.1f}%ì˜ ì„±ëŠ¥ ê°œì„ **ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.",
            "",
            "**ì£¼ìš” ì„±ê³¼:**"
        ]
        
        if avg_improvement > 30:
            conclusion_lines.append("âœ… **ë§¤ìš° ì„±ê³µì ì¸ ìµœì í™”**: ì‚¬ìš©ì ê²½í—˜ í¬ê²Œ ê°œì„ ")
        elif avg_improvement > 15:
            conclusion_lines.append("âœ… **ì„±ê³µì ì¸ ìµœì í™”**: ëˆˆì— ë„ëŠ” ì„±ëŠ¥ í–¥ìƒ")
        elif avg_improvement > 5:
            conclusion_lines.append("âš ï¸ **ë¶€ë¶„ì  ì„±ê³µ**: ì¼ë¶€ ì˜ì—­ì—ì„œ ê°œì„  í•„ìš”")
        else:
            conclusion_lines.append("ğŸ”´ **ìµœì í™” ì¬ê²€í†  í•„ìš”**: ê·¼ë³¸ì ì¸ ì ‘ê·¼ ë°©ì‹ ë³€ê²½ ê²€í† ")
        
        conclusion_lines.extend([
            "",
            "**í•µì‹¬ í•™ìŠµì‚¬í•­:**",
            "1. ë‹¤ì¸µ ìºì‹± ì „ëµì´ ê°€ì¥ íš¨ê³¼ì ì¸ ìµœì í™” ê¸°ë²•ìœ¼ë¡œ í™•ì¸",
            "2. ë¹„ë™ê¸° ì²˜ë¦¬ë¡œ I/O ë°”ìš´ë“œ ì‘ì—…ì˜ ì„±ëŠ¥ í–¥ìƒ ê°€ëŠ¥",
            "3. ì§€ëŠ¥í˜• ë°°ì¹˜ ì²˜ë¦¬ë¡œ API ë¹„ìš© ì ˆê°ê³¼ ì„±ëŠ¥ í–¥ìƒ ë™ì‹œ ë‹¬ì„±",
            "",
            "**í–¥í›„ ì§€ì†ì  ê°œì„ ì„ ìœ„í•œ ì œì–¸:**",
            "- ì •ê¸°ì ì¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹ ë° ëª¨ë‹ˆí„°ë§ ì²´ê³„ êµ¬ì¶•",
            "- ì‚¬ìš©ì í”¼ë“œë°± ê¸°ë°˜ ìµœì í™” ìš°ì„ ìˆœìœ„ ì¡°ì •",
            "- ì‹ ê¸°ìˆ  ë™í–¥ íŒŒì•… ë° ì„ ì œì  ë„ì… ê²€í† "
        ])
        
        return "\n".join(conclusion_lines)
    
    def _calculate_key_improvements(self, baseline: Dict, optimized: Dict) -> Dict[str, float]:
        """ì£¼ìš” ê°œì„  ì§€í‘œ ê³„ì‚°"""
        improvements = {}
        
        # ì„ë² ë”© ì²˜ë¦¬ëŸ‰
        if ('embedding' in baseline and 'individual_throughput' in baseline['embedding'] and
            'embedding' in optimized and 'throughput' in optimized['embedding']):
            base_val = baseline['embedding']['individual_throughput']
            opt_val = optimized['embedding']['throughput']
            improvements['ì„ë² ë”© ì²˜ë¦¬ëŸ‰'] = ((opt_val - base_val) / base_val) * 100
        
        # ê²€ìƒ‰ ì²˜ë¦¬ëŸ‰
        if ('search' in baseline and 'queries_per_second' in baseline['search'] and
            'search' in optimized and 'queries_per_second' in optimized['search']):
            base_val = baseline['search']['queries_per_second']
            opt_val = optimized['search']['queries_per_second']
            improvements['ê²€ìƒ‰ ì²˜ë¦¬ëŸ‰'] = ((opt_val - base_val) / base_val) * 100
        
        # ì‘ë‹µ ì‹œê°„
        if ('end_to_end' in baseline and 'avg_total_response_time' in baseline['end_to_end'] and
            'chatbot' in optimized and 'avg_response_time' in optimized['chatbot']):
            base_val = baseline['end_to_end']['avg_total_response_time']
            opt_val = optimized['chatbot']['avg_response_time']
            improvements['ì‘ë‹µ ì‹œê°„'] = ((base_val - opt_val) / base_val) * 100  # ì‹œê°„ì€ ê°ì†Œê°€ ê°œì„ 
        
        return improvements
    
    def _calculate_detailed_improvements(self, baseline: Dict, optimized: Dict) -> Dict[str, Dict[str, float]]:
        """ìƒì„¸ ê°œì„  ì§€í‘œ ê³„ì‚°"""
        improvements = {}
        
        # ìºì‹± íš¨ê³¼
        caching_improvements = {}
        if 'embedding' in optimized and 'cache_hit_rate' in optimized['embedding']:
            hit_rate = optimized['embedding']['cache_hit_rate'] * 100
            if hit_rate > 0:
                caching_improvements['ì„ë² ë”© ìºì‹œ ì ì¤‘ë¥ '] = hit_rate
        
        if 'search' in optimized and 'cache_hit_rate' in optimized['search']:
            hit_rate = optimized['search']['cache_hit_rate'] * 100
            if hit_rate > 0:
                caching_improvements['ê²€ìƒ‰ ìºì‹œ ì ì¤‘ë¥ '] = hit_rate
        
        if caching_improvements:
            improvements['ìºì‹± ìµœì í™”'] = caching_improvements
        
        # ë°°ì¹˜ ì²˜ë¦¬ íš¨ê³¼
        if ('embedding' in baseline and 'embedding' in optimized and
            'individual_throughput' in baseline['embedding'] and 'throughput' in optimized['embedding']):
            base_throughput = baseline['embedding']['individual_throughput']
            opt_throughput = optimized['embedding']['throughput']
            batch_improvement = ((opt_throughput - base_throughput) / base_throughput) * 100
            if batch_improvement > 0:
                improvements['ë°°ì¹˜ ì²˜ë¦¬'] = {'ì²˜ë¦¬ëŸ‰ ê°œì„ ': batch_improvement}
        
        return improvements
    
    def save_report(self, report_content: str, filename: str = None) -> Path:
        """ë³´ê³ ì„œë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"optimization_report_{timestamp}.md"
        
        filepath = self.reports_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        return filepath
    
    def create_performance_charts(self, baseline: Dict, optimized: Dict) -> List[Path]:
        """ì„±ëŠ¥ ë¹„êµ ì°¨íŠ¸ ìƒì„± (ì„ íƒì‚¬í•­)"""
        chart_paths = []
        
        try:
            # ì„±ëŠ¥ ë¹„êµ ì°¨íŠ¸ ë°ì´í„° ì¤€ë¹„
            metrics = []
            baseline_vals = []
            optimized_vals = []
            
            # ì£¼ìš” ì§€í‘œ ì¶”ì¶œ
            if 'embedding' in baseline and 'embedding' in optimized:
                if 'individual_throughput' in baseline['embedding'] and 'throughput' in optimized['embedding']:
                    metrics.append('ì„ë² ë”© ì²˜ë¦¬ëŸ‰')
                    baseline_vals.append(baseline['embedding']['individual_throughput'])
                    optimized_vals.append(optimized['embedding']['throughput'])
            
            if 'search' in baseline and 'search' in optimized:
                if 'queries_per_second' in baseline['search'] and 'queries_per_second' in optimized['search']:
                    metrics.append('ê²€ìƒ‰ ì²˜ë¦¬ëŸ‰')
                    baseline_vals.append(baseline['search']['queries_per_second'])
                    optimized_vals.append(optimized['search']['queries_per_second'])
            
            if metrics:
                # ì°¨íŠ¸ ìƒì„±
                plt.figure(figsize=(12, 6))
                
                x = range(len(metrics))
                width = 0.35
                
                plt.bar([i - width/2 for i in x], baseline_vals, width, label='ê¸°ì¤€ì„ ', alpha=0.8)
                plt.bar([i + width/2 for i in x], optimized_vals, width, label='ìµœì í™” í›„', alpha=0.8)
                
                plt.xlabel('ì„±ëŠ¥ ì§€í‘œ')
                plt.ylabel('ê°’')
                plt.title('ì„±ëŠ¥ ìµœì í™” ë¹„êµ')
                plt.xticks(x, metrics)
                plt.legend()
                plt.grid(True, alpha=0.3)
                
                # ì°¨íŠ¸ ì €ì¥
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                chart_path = self.reports_dir / f"performance_comparison_{timestamp}.png"
                plt.savefig(chart_path, dpi=300, bbox_inches='tight')
                plt.close()
                
                chart_paths.append(chart_path)
            
        except ImportError:
            print("âš ï¸ matplotlibì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ì°¨íŠ¸ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        except Exception as e:
            print(f"âš ï¸ ì°¨íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        
        return chart_paths


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - ì˜ˆì‹œ"""
    # ì˜ˆì‹œ ë°ì´í„° (ì‹¤ì œë¡œëŠ” performance_measurement.pyì™€ speed_optimization.pyì—ì„œ ìƒì„±ëœ ë°ì´í„° ì‚¬ìš©)
    baseline_results = {
        'embedding': {
            'individual_throughput': 2.5,
            'individual_avg_time': 0.4
        },
        'search': {
            'queries_per_second': 8.3,
            'avg_search_time': 0.12
        },
        'end_to_end': {
            'avg_total_response_time': 4.2,
            'questions_per_minute': 14.3
        }
    }
    
    optimized_results = {
        'embedding': {
            'throughput': 6.8,
            'avg_time_per_text': 0.15,
            'cache_hit_rate': 0.75
        },
        'search': {
            'queries_per_second': 18.6,
            'avg_time_per_query': 0.054,
            'cache_hit_rate': 0.62
        },
        'chatbot': {
            'avg_response_time': 1.8,
            'questions_per_minute': 33.3,
            'optimization_stats': {
                'embedding': {'hit_rate': 0.75},
                'vector_db': {'hit_rate': 0.62},
                'response_cache_size': 45
            }
        }
    }
    
    # ë³´ê³ ì„œ ìƒì„±
    generator = OptimizationReportGenerator()
    report = generator.generate_comprehensive_report(baseline_results, optimized_results)
    
    # íŒŒì¼ ì €ì¥
    report_path = generator.save_report(report)
    print(f"âœ… ìµœì í™” ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {report_path}")
    
    # ì°¨íŠ¸ ìƒì„± (ì„ íƒì‚¬í•­)
    chart_paths = generator.create_performance_charts(baseline_results, optimized_results)
    if chart_paths:
        print(f"ğŸ“Š ì„±ëŠ¥ ì°¨íŠ¸ ìƒì„± ì™„ë£Œ: {chart_paths}")


if __name__ == "__main__":
    main()